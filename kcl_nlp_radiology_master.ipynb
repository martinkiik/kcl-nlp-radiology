{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatically labelling radiology reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "# NLP imports\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "#gensim for word embedding featurization\n",
    "import gensim\n",
    "from collections import namedtuple\n",
    "\n",
    "#misc\n",
    "import glob\n",
    "import os.path\n",
    "import multiprocessing\n",
    "import random\n",
    "\n",
    "\n",
    "sys.path.append(\"C:\\\\Users\\\\marti\\\\Dropbox\\\\1. KCL\\\\1. Current Modules\\\\6. SPM\\\\1. Analysis\\\\NLP\\\\rad-report-annotator\")\n",
    "import RadReportAnnotator as ra\n",
    "# pd.set_option('display.max_columns', None)\n",
    "\n",
    "# dir(RadReportAnnotator) # list available functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize some folder paths\n",
    "reports = \"C:\\\\Users\\\\marti\\\\Dropbox\\\\1. KCL\\\\1. Current Modules\\\\6. SPM\\\\1. Analysis\\\\NLP\\\\Data\\\\20080801 20190131 Neuro and SLAM MRI Heads.csv\"\n",
    "reports_path = \"C:\\\\Users\\\\marti\\\\Dropbox\\\\1. KCL\\\\1. Current Modules\\\\6. SPM\\\\1. Analysis\\\\NLP\\\\Data\\\\Reports\"\n",
    "\n",
    "test_labels = \"C:\\\\Users\\\\marti\\\\Dropbox\\\\1. KCL\\\\1. Current Modules\\\\6. SPM\\\\1. Analysis\\\\NLP\\\\Data\\\\output_test.xlsx\"\n",
    "binary_labels = \"C:\\\\Users\\\\marti\\\\Dropbox\\\\1. KCL\\\\1. Current Modules\\\\6. SPM\\\\1. Analysis\\\\NLP\\\\Data\\\\output_binary_combined.xlsx\"\n",
    "labels_path = \"C:\\\\Users\\\\marti\\\\Dropbox\\\\1. KCL\\\\1. Current Modules\\\\6. SPM\\\\1. Analysis\\\\NLP\\\\Data\\\\Labels\"\n",
    "\n",
    "labels = binary_labels # use either test_labels or binary_labels for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pandas dataframes\n",
    "df_raw = pd.read_csv(reports,encoding = \"ISO-8859-1\", dtype={\"Code\": 'O',}) # Column 17 \"Code\" reports a mixed value error on import without specifying it as Python Object \n",
    "df_labels = pd.read_excel(labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove NaN, <18 yo, and brief reports.\n",
    "df_raw = df_raw[~df_raw[\"Report Text\"].isnull()] # remove the lines with missing reports\n",
    "df_raw = df_raw[~df_raw['DOB'].isnull()] # remove missing DOB\n",
    "df_raw = df_raw[df_raw['Report Text'].map(len) > 10] # report length greater than X\n",
    "df_raw = df_raw[(df_raw['Event Year'].astype(int) - df_raw['DOB'].str[-4:].astype(int))>18] #\n",
    "df_raw = df_raw.reset_index()\n",
    "\n",
    "#df_raw.head()\n",
    "# dob_mask.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replicate the format of Sinai data, but use csv - this means we can't use all of their code\n",
    "# Sinai code uses XLS, so would have to cap df_raw_filter to some smaller subset\n",
    "\n",
    "# print(df_raw.columns)\n",
    "df_raw_filter = df_raw.loc[:10000,[\"Accession\", \"Report Text\"]]\n",
    "df_raw_filter.columns=[\"Accession Number\", \"Report Text\"]\n",
    "df_raw_filter.to_csv(reports_path+'\\\\raw_data_filtered.csv',header = True, index = False)\n",
    "reports_filter = reports_path+'\\\\raw_data_filtered.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_columns = [' Accession ', ' Fazekas ', ' Supratentorial Atrophy ',\n",
    "        ' Infratentorial Atrophy ', ' Mass ', ' Vascular ', ' Damage ',\n",
    "        ' Acute Stroke ', ' Haemorrhage ', ' Hydrocephalus ',\n",
    "        ' White Matter Inflammation ', ' Foreign Body ', ' Intracranial ',\n",
    "        ' Extracranial '] # select accession and other variables\n",
    "df_labels_filter = df_labels[filter_columns] \n",
    "df_labels_filter = df_labels_filter.rename(columns = {' Accession ':'Accession Number'}) # rename to match the other file\n",
    "\n",
    "# We can use excel for this one bc # of labels will always < 65k. Also, build_train_test_corpus requires xls\n",
    "# df_labels_filter[\"Accession Number\"] = df_labels_filter.loc[:,\"Accession Number\"].str[3:]\n",
    "df_labels_filter.to_excel(labels_path+'\\\\labels_filtered.xls',header = True, index = False)\n",
    "labels_filter = labels_path+'\\\\labels_filtered.xls'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     10001\n",
       "unique        2\n",
       "top       False\n",
       "freq       8846\n",
       "Name: Accession Number, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is a replacement of the get_label_indeces function\n",
    "# ra.get_labeled_indices(reports_path, labels_filter, train_index_override)\n",
    "label_ids = df_labels_filter['Accession Number']\n",
    "mask_labels = df_raw_filter['Accession Number'].isin(label_ids.tolist()) # true/false for the ones in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                             | 27/10001 [00:00<00:37, 265.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing reports\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 10001/10001 [00:14<00:00, 675.72it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a list of stopwords and process data\n",
    "stop_words = set(stopwords.words('english')) # could add MRI etc to this\n",
    "preprocessed = ra.preprocess_data(df_raw_filter,stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██▊                                                                         | 363/10001 [00:00<00:02, 3603.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating n-grams\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 10001/10001 [00:01<00:00, 6455.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique n-grams: 430142\n",
      "number of unique n-grams after filtering out low frequency tokens: 47703\n"
     ]
    }
   ],
   "source": [
    "# Create n-grams\n",
    "N_THRESH_CORPUS = 3 # ignore any n-grams that appear fewer than N times in the entire corpus\n",
    "n_gram_sizes = [1,2,3,4] # need to make sure we can use 4 - their examples are 3 max \n",
    "ngram_list = ra.create_ngrams(preprocessed, mask_labels, n_gram_sizes, N_THRESH_CORPUS)\n",
    "\n",
    "## notes from david: set n_gram = 1 for gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the sets for training & testing\n",
    "# Note that this function requires xls for label file\n",
    "# This can take a while - could add an indicator in the future\n",
    "\n",
    "TRAIN_INDEX_OVERRIDE = [0] # This would be a list of indices for which to ignore the labels if all of the training data was labelled\n",
    "corpus, train_corpus, test_corpus, dictionary, labeled_indices = ra.build_train_test_corpus(df_raw_filter, ngram_list, labels_filter, TRAIN_INDEX_OVERRIDE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm pretty sure \"d2v_inputs\" is the same as \"preprocessed\" but generate_labeled_data_features requires both,\n",
    "# and I can't really tell how they're different\n",
    "\n",
    "d2v_inputs = ra.remove_infrequent_tokens(preprocessed, N_THRESH_CORPUS, mask_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8846 unlabeled reports for featurization, 1155 labeled reports for modeling\n"
     ]
    }
   ],
   "source": [
    "# Create training sets\n",
    "unlabeled_corpus, labeled_corpus, total_unlabeled_words = ra.build_d2v_corpora(df_raw_filter, preprocessed,labeled_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish variables\n",
    "D2V_EPOCHS = 20 # recommended by Sinai\n",
    "DIM_DOC2VEC = 50 # Dimensionality of doc2vec manifold; recommend value in 50 to 400\n",
    "W2V_DM = 1\n",
    "W2V_WINDOW = 3\n",
    "SILVER_THRESHOLD = \"mean\" # can be [\"mean\",\"mostlikely\"]\n",
    "DO_PARAGRAPH_VECTOR = False # True to use word2vec-based paragraph vector embedding fatures\n",
    "DO_BOW = False\n",
    "DO_WORD2VEC = True # True to use word2vec-based average word embedding fatures\n",
    "N_THRESH_OUTCOMES = 1 # do not train models for labels that don't have at least this many positive and negative examples\n",
    "pred_type = \"combined\" # a label for results\n",
    "ASSIGNFOLD_USING_ROW=False\n",
    "SILVER_THRESHOLD=\"fiftypct\"\n",
    "\n",
    "# Initiate the class based on demo notebookhttps://github.com/aisinai/rad-report-annotator/blob/master/RadReportAnnotator.py\n",
    "# MRIannotator = ra.RadReportAnnotator(report_dir_path=os.path.join(reports_path),validation_file_path=os.path.join(labels_filter))\n",
    " # MRIannotator.define_config(DO_BOW=True,\n",
    "#                            DO_WORD2VEC=False,\n",
    "#                            DO_PARAGRAPH_VECTOR=False,\n",
    "#                            N_GRAM_SIZES=[1,2,3],\n",
    "#                            SILVER_THRESHOLD=\"fiftypct\",\n",
    "#                            NAME_UNID_REPORTS = \"ACCID\",\n",
    "#                            NAME_TEXT_REPORTS =\"REPORT\",\n",
    "#                            N_THRESH_CORPUS=10,\n",
    "#                            N_THRESH_OUTCOMES=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_d2v(unlabeled_docs, labeled_docs, D2V_EPOCH, DIM_DOC2VEC, W2V_DM, W2V_WINDOW, total_unlabeled_words):\n",
    "\t\"\"\"\n",
    "\tTrain doc2vec/word2vec model.\n",
    "\tArgs:\n",
    "\t\tunlabeled_docs: unlabeled corpus\n",
    "\t\tlabeled_docs: labeled corpus\n",
    "\t\tD2V_EPOCHS: number of epochs to train d2v model; 20 has worked well in our experiments; parameter for gensim doc2vec\n",
    "\t\tDIM_DOC2VEC: dimensionality of embedding vectors, we explored values 50-800; parameter for gensim doc2vec\n",
    "\t\tW2V_DM: 1 is PV-DM, otherwise PV-DBOW; parameter for gensim doc2vec\n",
    "\t\tW2V_WINDOW: number of words window to use  in doc2vec model; parameter for gensim doc2vec\n",
    "\t\ttotal_unlabeled_words: total words in unlabeled corpus; argument for gensim doc2vec\n",
    "\tReturns:\n",
    "\t\td2vmodel: trained doc2vec model.\n",
    "\t\"\"\"\n",
    "\n",
    "\tcores = multiprocessing.cpu_count()\n",
    "\tassert gensim.models.doc2vec.FAST_VERSION > -1, \"speed up\"\n",
    "\tprint(\"started doc2vec training\")\n",
    "\td2vmodel = gensim.models.Doc2Vec(dm=W2V_DM, size=DIM_DOC2VEC, window=W2V_WINDOW, negative=5, hs=0, min_count=2, workers=cores)\n",
    "\td2vmodel.build_vocab(unlabeled_docs + labeled_docs)  \n",
    "\td2vmodel.train(unlabeled_docs, total_words=total_unlabeled_words, epochs=D2V_EPOCH)\n",
    "\tprint(\"finished doc2vec training\")\n",
    "\treturn d2vmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started doc2vec training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marti\\dropbox\\15607~1.kcl\\1c4ea~1.cur\\6c9d3~1.spm\\19e96~1.ana\\nlp\\lib\\site-packages\\gensim\\models\\doc2vec.py:574: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished doc2vec training\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "d2vmodel = train_d2v(unlabeled_corpus, labeled_corpus, D2V_EPOCHS, DIM_DOC2VEC, \n",
    "                        W2V_DM, W2V_WINDOW, total_unlabeled_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1155 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1155/1155 [00:00<00:00, 1584.25it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create features for Lasso log reg\n",
    "bow_matrix, pv_matrix, w2v_matrix, accid_list, orig_text, orig_input = ra.generate_labeled_data_features(labels_filter,labeled_indices,DIM_DOC2VEC, df_raw_filter,  \n",
    "                                                                                                         preprocessed, DO_PARAGRAPH_VECTOR, DO_WORD2VEC, dictionary, \n",
    "                                                                                                         corpus, d2vmodel, d2v_inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataframe of labels to be used in Lasso logistic regressions\n",
    "# EDITED range in for loop to skip the IDs as variables; removed IDs right after loop\n",
    "def generate_outcomes(labeled_file, accid_list, N_THRESH_OUTCOMES):\n",
    "\n",
    "\t\"\"\"\n",
    "\tGenerate dataframe of labels to be used in Lasso logistic regressions\n",
    "\tArgs:\n",
    "\t\tlabeled_file: path to file with labels and accession ids\n",
    "\t\taccid_list: list of accession ids of each row in the labeled data that are also present in exported reports; \n",
    "\t\t\t\t \tneeded to eliminate labeled reports for which we have no text (mistranscribed accession IDs, etc.)\n",
    "\t\tN_THRESH_OUTCOMES: eliminate outcomes that don't have this many positive / negative examples\n",
    "\tReturns:\n",
    "\t\teligible_outcomes_aligned: dataframe of labels eligible for prediction\n",
    "\t\tall_outcomes_aligned: dataframe of all labels\n",
    "\t\tN_LABELS: total number of labels we predict\n",
    "\t\toutcome_header_list: list of headers corresponding to each label\n",
    "\t\"\"\"    \n",
    "\n",
    "    outcomes = pd.read_excel(labeled_file)\n",
    "    outcomes.set_index('Accession Number')\n",
    "    outcomes_aligned2 = pd.DataFrame(data=accid_list, index=accid_list, columns=['Accession Number'])\n",
    "    all_outcomes_aligned = pd.merge(outcomes_aligned2, outcomes, sort=False)\n",
    "    \n",
    "    N_LABELS = all_outcomes_aligned.shape[1]\n",
    "    outcome_remove=[]\n",
    "    print('total labels:'+str(N_LABELS))\n",
    "\n",
    "    for i in range(1,N_LABELS): #start from 1 to skip the IDs\n",
    "        check=sum(all_outcomes_aligned.iloc[:,i])\n",
    "\n",
    "        if(check<N_THRESH_OUTCOMES):\n",
    "            outcome_remove.append(i)\n",
    "        elif(check>((all_outcomes_aligned.shape)[0]-N_THRESH_OUTCOMES)):\n",
    "            outcome_remove.append(i)\n",
    "        elif(math.isnan(check)):\n",
    "            outcome_remove.append(i)\n",
    "\n",
    "    outcome_remove.append(0) # added this to remove the accession IDs as \"outcomes\"\n",
    "    eligible_outcomes_aligned=all_outcomes_aligned.drop(all_outcomes_aligned.columns[outcome_remove],axis=1)\n",
    "\n",
    "    N_LABELS=eligible_outcomes_aligned.shape[1]\n",
    "    print(\"labels eligible for inference:\"+str(N_LABELS))\n",
    "\n",
    "    outcome_header_list=list(eligible_outcomes_aligned)\n",
    "    outcome_header_list=[x.replace(\",\",\".\") for x in outcome_header_list]\n",
    "    outcome_header_list=\",\".join(outcome_header_list)\n",
    "\t\n",
    "    return eligible_outcomes_aligned,all_outcomes_aligned, N_LABELS, outcome_header_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total labels:14\n",
      "labels eligible for inference:1\n"
     ]
    }
   ],
   "source": [
    "# Create input for Lasso\n",
    "eligible_outcomes_aligned, all_outcomes_aligned, N_LABELS, outcome_header_list = generate_outcomes(labels_filter, \n",
    "                                                                                              accid_list, N_THRESH_OUTCOMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate predictor_matrix before generating silver standard labels -- use whatever features are generated (word2vec average word embeddings, bow features, paragraph vector matrix)\n",
    "if(DO_BOW and DO_WORD2VEC and DO_PARAGRAPH_VECTOR): combined=np.hstack((bow_matrix,w2v_matrix,pv_matrix))\n",
    "\n",
    "if(DO_BOW and DO_WORD2VEC and not DO_PARAGRAPH_VECTOR): combined=np.hstack((bow_matrix,w2v_matrix))\n",
    "if(DO_BOW and not DO_WORD2VEC and DO_PARAGRAPH_VECTOR): combined=np.hstack((bow_matrix,pv_matrix))\n",
    "if(not DO_BOW and DO_WORD2VEC and DO_PARAGRAPH_VECTOR): combined=np.hstack((w2v_matrix,pv_matrix))\n",
    "\n",
    "if(DO_BOW and not DO_WORD2VEC and not DO_PARAGRAPH_VECTOR): combined=bow_matrix\n",
    "if(not DO_BOW and DO_WORD2VEC and not DO_PARAGRAPH_VECTOR): combined=w2v_matrix\n",
    "if(not DO_BOW and not DO_WORD2VEC and DO_PARAGRAPH_VECTOR): combined=pv_matrix\t\t\n",
    "\n",
    "predictor_matrix = combined\n",
    "\n",
    "headers=[]\n",
    "if(DO_BOW): \t\t\t\theaders=headers + [dictionary[i] for i in dictionary]\n",
    "if(DO_WORD2VEC): \t\t\theaders=headers + [\"W2V\"+str(i) for i in range(0,DIM_DOC2VEC)]\n",
    "if(DO_PARAGRAPH_VECTOR): \theaders=headers + [\"PV\"+str(i) for i in range(0,DIM_DOC2VEC)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slight modifications to swap out indexing in TF FP TN FN and the randomization process\n",
    "def calc_auc(predictor_matrix,eligible_outcomes_aligned, all_outcomes_aligned,N_LABELS, pred_type, header,ASSIGNFOLD_USING_ROW=False):\n",
    "\n",
    "    train_proportion = 0.6\n",
    "    lasso_models={}\n",
    "    model_types = [\"Lasso\"]\n",
    "\n",
    "    # shuffle the data\n",
    "    eligible_outcomes_aligned.reindex(np.random.permutation(eligible_outcomes_aligned.index)) # swapped out np.random.shuffle(r)\n",
    "\n",
    "    r = list(range(eligible_outcomes_aligned.shape[0]))\n",
    "    np.random.shuffle(r)\n",
    "\n",
    "    assignfold = pd.DataFrame(data=r, columns=['train'])\n",
    "    cutoff = np.floor(train_proportion*eligible_outcomes_aligned.shape[0]).astype(int)\n",
    "\n",
    "    train=assignfold['train']<cutoff\n",
    "    test=assignfold['train']>=cutoff\n",
    "\n",
    "    print(test)\n",
    "    N_TRAIN=eligible_outcomes_aligned.iloc[:cutoff].shape[0]\n",
    "    N_HELDOUT = eligible_outcomes_aligned.iloc[cutoff:].shape[0]\n",
    "\n",
    "    #train = eligible_outcomes_aligned.iloc[:cutoff,[0]]\n",
    "    #test = eligible_outcomes_aligned.iloc[cutoff:,[0]]\n",
    "\n",
    "    print(\"n_train in modeling=\"+str(N_TRAIN))\n",
    "    print(\"n_test in modeling=\"+str(N_HELDOUT))\n",
    "\n",
    "    confusion = pd.DataFrame(data=np.zeros(shape=(eligible_outcomes_aligned.shape[1]*len(model_types),6),dtype=np.int),columns=['Label (with calcs on held out 40 pct)','AUC','True +','False +','True -','False -'])\n",
    "\n",
    "    resultrow=0\n",
    "\n",
    "    for i in range(0,N_LABELS):\n",
    "            PROCEED=True;\n",
    "            #need to make sure we don't have an invalid setting -- ie, a train[x] set of labels that is uniform, else Lasso regression fails\n",
    "            if(len(set(eligible_outcomes_aligned.ix[train,i].tolist())))==1:\n",
    "                PROCEED=False;\n",
    "                raise ValueError (\"fed label to lasso regression with no variation - cannot compute - please investigate data\")\n",
    "\n",
    "            if(PROCEED):\n",
    "\n",
    "                for model_type in model_types:\n",
    "                    if(model_type==\"Lasso\"):\n",
    "                        parameters = { \"penalty\": ['l1'], \n",
    "                                       \"C\": [64,32,16,8,4,2,1,0.5,0.25,0.1,0.05,0.025,0.01,0.005]\n",
    "                                     }\n",
    "                        try:\n",
    "                            cv = StratifiedKFold(n_splits=5)\n",
    "                            grid_search = GridSearchCV(LogisticRegression(solver='liblinear'), param_grid=parameters, scoring='neg_log_loss', cv=cv) ## can change liblinear to \"lbfgs\"\n",
    "                            grid_search.fit(predictor_matrix[train,:],np.array(eligible_outcomes_aligned.ix[train,i]))\t\t\t\t\n",
    "                            best_parameters0 = grid_search.best_estimator_.get_params()\n",
    "                            model0 = LogisticRegression(**best_parameters0)\t\t\t\t\t\n",
    "                        except:\n",
    "                            raise ValueError (\"error in lasso regression - likely data issue, may involve rare labels - please investigate data\")                        \n",
    "                    model0.fit(predictor_matrix[np.array(train),:],eligible_outcomes_aligned.ix[train,i])\n",
    "                    pred0=model0.predict_proba(predictor_matrix[np.array(test),:])[:,1]\n",
    "                    coef = pd.concat([ pd.DataFrame(headers),pd.DataFrame(np.transpose(model0.coef_))], axis = 1)\t\n",
    "                    df0 = pd.DataFrame({'predict':pred0,'target':eligible_outcomes_aligned.ix[test,i], 'label':all_outcomes_aligned['Accession Number'][test]})\n",
    "\n",
    "                    calc_auc=roc_auc_score(np.array(df0['target']),np.array(df0['predict']))\n",
    "                    if(i%10==0):\n",
    "                        print(\"i=\"+str(i))\n",
    "                    save_name=str(list(eligible_outcomes_aligned.columns.values)[i])\n",
    "\n",
    "                    target_predicted=''.join(e for e in save_name if e.isalnum())\n",
    "\n",
    "                    #confusion: outcome TP TN FP FN\n",
    "                    thresh = np.mean(df0['target'])\n",
    "                    FP=0\n",
    "                    FN=0\n",
    "                    TP=0\n",
    "                    TN=0\n",
    "                    for j in df0.index:\n",
    "                        cpred=df0.ix[j][0] # changed from 1 to 0 \n",
    "                        ctarget = df0.ix[j][1] # changed from 2 to 1\n",
    "                        \n",
    "                        if cpred>=thresh and ctarget==1:\n",
    "                            TP+=1\n",
    "                        if cpred<thresh and ctarget==1:\n",
    "                            FN+=1\n",
    "                        if cpred>=thresh and ctarget==0:\n",
    "                            FP+=1\n",
    "                        if cpred<thresh and ctarget==0:\n",
    "                            TN+=1\n",
    "\n",
    "                    #save results\t\t\n",
    "                    confusion.iloc[resultrow,0]=list(eligible_outcomes_aligned.columns.values)[i]\n",
    "                    confusion.iloc[resultrow,1]=calc_auc\n",
    "                    confusion.iloc[resultrow,2]=TP\n",
    "                    confusion.iloc[resultrow,3]=FP\n",
    "                    confusion.iloc[resultrow,4]=TN\n",
    "                    confusion.iloc[resultrow,5]=FN\n",
    "\n",
    "                    #let's rebuild model using all data before we save it to use for prediction;\n",
    "                    try:\n",
    "                        model0 = LogisticRegression(**best_parameters0)\t\n",
    "                        model0.fit(predictor_matrix,eligible_outcomes_aligned.ix[:,i])                \n",
    "                        lasso_models[i]=model0\n",
    "                    except:\n",
    "                        raise ValueError (\"error in lasso regression - likely data issue, may involve rare labels - please investigate data\")                        \n",
    "\n",
    "                    resultrow+=1\n",
    "\n",
    "    confusion.set_index(confusion.columns[0],inplace=True)\n",
    "    return lasso_models, confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       False\n",
      "1        True\n",
      "2       False\n",
      "3       False\n",
      "4        True\n",
      "        ...  \n",
      "1150    False\n",
      "1151     True\n",
      "1152     True\n",
      "1153    False\n",
      "1154    False\n",
      "Name: train, Length: 1155, dtype: bool\n",
      "n_train in modeling=693\n",
      "n_test in modeling=462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marti\\dropbox\\15607~1.kcl\\1c4ea~1.cur\\6c9d3~1.spm\\19e96~1.ana\\nlp\\lib\\site-packages\\ipykernel_launcher.py:37: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "c:\\users\\marti\\dropbox\\15607~1.kcl\\1c4ea~1.cur\\6c9d3~1.spm\\19e96~1.ana\\nlp\\lib\\site-packages\\pandas\\core\\indexing.py:961: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  return getattr(section, self.name)[new_key]\n",
      "c:\\users\\marti\\dropbox\\15607~1.kcl\\1c4ea~1.cur\\6c9d3~1.spm\\19e96~1.ana\\nlp\\lib\\site-packages\\ipykernel_launcher.py:51: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "c:\\users\\marti\\dropbox\\15607~1.kcl\\1c4ea~1.cur\\6c9d3~1.spm\\19e96~1.ana\\nlp\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "c:\\users\\marti\\dropbox\\15607~1.kcl\\1c4ea~1.cur\\6c9d3~1.spm\\19e96~1.ana\\nlp\\lib\\site-packages\\ipykernel_launcher.py:56: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "c:\\users\\marti\\dropbox\\15607~1.kcl\\1c4ea~1.cur\\6c9d3~1.spm\\19e96~1.ana\\nlp\\lib\\site-packages\\pandas\\core\\indexing.py:961: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  return getattr(section, self.name)[new_key]\n",
      "c:\\users\\marti\\dropbox\\15607~1.kcl\\1c4ea~1.cur\\6c9d3~1.spm\\19e96~1.ana\\nlp\\lib\\site-packages\\ipykernel_launcher.py:59: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "c:\\users\\marti\\dropbox\\15607~1.kcl\\1c4ea~1.cur\\6c9d3~1.spm\\19e96~1.ana\\nlp\\lib\\site-packages\\pandas\\core\\indexing.py:961: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  return getattr(section, self.name)[new_key]\n",
      "c:\\users\\marti\\dropbox\\15607~1.kcl\\1c4ea~1.cur\\6c9d3~1.spm\\19e96~1.ana\\nlp\\lib\\site-packages\\ipykernel_launcher.py:75: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "c:\\users\\marti\\dropbox\\15607~1.kcl\\1c4ea~1.cur\\6c9d3~1.spm\\19e96~1.ana\\nlp\\lib\\site-packages\\ipykernel_launcher.py:76: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marti\\dropbox\\15607~1.kcl\\1c4ea~1.cur\\6c9d3~1.spm\\19e96~1.ana\\nlp\\lib\\site-packages\\ipykernel_launcher.py:98: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n"
     ]
    }
   ],
   "source": [
    "# Create the lasso model using the function defined above\n",
    "lasso_models, accuracy = calc_auc(predictor_matrix, eligible_outcomes_aligned,all_outcomes_aligned,N_LABELS, pred_type,headers,ASSIGNFOLD_USING_ROW) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:01<00:00, 1153.52it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:01<00:00, 1987.10it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:00<00:00, 2357.92it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:00<00:00, 2272.46it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:00<00:00, 2212.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1002.70it/s]\n",
      "C:\\Users\\marti\\Dropbox\\1. KCL\\1. Current Modules\\6. SPM\\1. Analysis\\NLP\\rad-report-annotator\\RadReportAnnotator.py:798: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  if(eligible_outcomes_aligned.ix[outcome_lookup[accno],k]!=pred_outcome_binary_df.iloc[i,k]):\n",
      "c:\\users\\marti\\dropbox\\15607~1.kcl\\1c4ea~1.cur\\6c9d3~1.spm\\19e96~1.ana\\nlp\\lib\\site-packages\\pandas\\core\\indexing.py:961: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  return getattr(section, self.name)[new_key]\n",
      "C:\\Users\\marti\\Dropbox\\1. KCL\\1. Current Modules\\6. SPM\\1. Analysis\\NLP\\rad-report-annotator\\RadReportAnnotator.py:803: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  pred_outcome_proba_df.iloc[i,k]=eligible_outcomes_aligned.ix[outcome_lookup[accno],k]\n",
      "C:\\Users\\marti\\Dropbox\\1. KCL\\1. Current Modules\\6. SPM\\1. Analysis\\NLP\\rad-report-annotator\\RadReportAnnotator.py:806: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  if(eligible_outcomes_aligned.ix[outcome_lookup[accno],k]!=pred_outcome_binary_df.iloc[i,k]):\n",
      "C:\\Users\\marti\\Dropbox\\1. KCL\\1. Current Modules\\6. SPM\\1. Analysis\\NLP\\rad-report-annotator\\RadReportAnnotator.py:807: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  pred_outcome_binary_df.iloc[i,k]=eligible_outcomes_aligned.ix[outcome_lookup[accno],k]\n"
     ]
    }
   ],
   "source": [
    "inferred_binary_labels, inferred_proba_labels = ra.write_silver_standard_labels(corpus,\n",
    "                                                  N_LABELS,\n",
    "                                                  eligible_outcomes_aligned, \n",
    "                                                  DIM_DOC2VEC, \n",
    "                                                  preprocessed, \n",
    "                                                  DO_BOW, \n",
    "                                                  DO_PARAGRAPH_VECTOR, \n",
    "                                                  DO_WORD2VEC, \n",
    "                                                  dictionary, \n",
    "                                                  d2vmodel, \n",
    "                                                  d2v_inputs, \n",
    "                                                  lasso_models_ra, \n",
    "                                                  accid_list, \n",
    "                                                  labeled_indices, \n",
    "                                                  df_raw_filter, \n",
    "                                                  SILVER_THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>True +</th>\n",
       "      <th>False +</th>\n",
       "      <th>True -</th>\n",
       "      <th>False -</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label (with calcs on held out 40 pct)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mass</th>\n",
       "      <td>0.959194</td>\n",
       "      <td>195</td>\n",
       "      <td>34</td>\n",
       "      <td>213</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            AUC  True +  False +  True -  \\\n",
       "Label (with calcs on held out 40 pct)                                      \n",
       " Mass                                  0.959194     195       34     213   \n",
       "\n",
       "                                       False -  \n",
       "Label (with calcs on held out 40 pct)           \n",
       " Mass                                       20  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_models_ra\n",
    "accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \tdef define_config(self, DO_BOW=True, DO_WORD2VEC=False, DO_PARAGRAPH_VECTOR=False,DO_SILVER_STANDARD=True,STEM_WORDS=True,N_GRAM_SIZES=[1],DIM_DOC2VEC=200,N_THRESH_CORPUS=1,N_THRESH_OUTCOMES=1,TRAIN_INDEX_OVERRIDE=[], SILVER_THRESHOLD=\"mean\", NAME_UNID_REPORTS=\"Accession Number\",NAME_TEXT_REPORTS=\"Report Text\"):\n",
    "# \t\t\"\"\"\n",
    "# \t\tSets parameters for RadReportAnnotator.\n",
    "# \t\tArgs:\n",
    "# \t\t\tDO_BOW: True to use indicator bag of words-based features (1 if word present in doc, 0 if not). \n",
    "# \t\t\tDO_WORD2VEC: True to use word2vec-based average word embedding fatures. \n",
    "# \t\t\tDO_PARAGRAPH_VECTOR: True to use word2vec-based paragraph vector embedding fatures. \n",
    "# \t\t\tDO_SILVER_STANDARD: True to infer labels for unlabeled reports.\n",
    "# \t\t\tSTEM_WORDS: True to stem words for BOW analysis; words are unstemmed in doc2vec analysis\n",
    "# \t\t\tN_GRAM_SIZES: Which set of n-grams to use in BOW analysis: [1] = 1 grams only, [3] = 3 grams only, [1,2,3] = 1, 2, and 3- grams.\n",
    "# \t\t\tDIM_DOC2VEC: Dimensionality of doc2vec manifold; recommend value in 50 to 400\n",
    "# \t\t\tN_THRESH_CORPUS: ignore any n-grams that appear fewer than N times in the entire corpus\n",
    "# \t\t\tN_THRESH_OUTCOMES: do not train models for labels that don't have at least this many positive and negative examples. \n",
    "# \t\t\tTRAIN_INDEX_OVERRIDE: list of accession numbers we force to be treated as unlabeled data even though they are labeled (ie, these will *not* be used in Lasso regressions). May be used if all of your reports are labeled, as some unlabeled reports are required for d2v training.\n",
    "# \t\t\tSILVER_THRESHOLD: how to threshold probability predictions in infer_labels to get binary labels. \n",
    "# \t\t\t                  can be [\"mean\",\"mostlikely\"]\n",
    "# \t\t\t                  mean sets any predicted probability greater than population mean to 1, else 0; e.g., prediction 0.10 in a label with average 0.05 is set to 1\n",
    "# \t\t\t                  mostlikely sets any predicted probability >50% to 1, otherwise 0\n",
    "# \t\t\t                  both settings have issues, and class imbalance is a major issue in training convolutional nets.\n",
    "# \t\t\t                  we recommend using probabilities if your model can accomodate it. \n",
    "#  \t\t\tNAME_UNID_REPORTS: column name of accession number / unique report id in the read-in *reports* file. provided for convenience as there may be many report files.\n",
    "# \t\t\tNAME_TEXT_REPORTS: column name of report text in the read-in reports file. provided for convenience as there may be many report files.\n",
    "# \t\tReturns:\n",
    "# \t\t\tNothing\n",
    "# \t\t\"\"\"\n",
    "\n",
    "# \t\tself.DO_BOW=DO_BOW #generate results for bag of words approach?\n",
    "# \t\tself.DO_WORD2VEC=DO_WORD2VEC #generate resultes (tfidf and avg weight) for word2vec approach?\n",
    "# \t\tself.DO_PARAGRAPH_VECTOR=DO_PARAGRAPH_VECTOR #generate results for paragraph vector approach?\n",
    "# \t\tself.DO_SILVER_STANDARD=DO_SILVER_STANDARD\t#generate silver standard labels?\n",
    "# \t\tself.STEM_WORDS=STEM_WORDS #should we stem words for BOW, LDA analysis? (we never stem words or doc2vec/w2v analysis, see below)\n",
    "# \t\tif not N_GRAM_SIZES in ([1],[2],[3],[1,2],[1,3],[1,2,3]):\n",
    "# \t\t\traise ValueError('Invalid N_GRAM_SIZES argument:'+str(N_GRAM_SIZES)+\", please review documentation for proper format (e.g., [1])\")\n",
    "# \t\tself.N_GRAM_SIZES = N_GRAM_SIZES  # how many n-grams to use in BOW, LDA analyses? [1] = 1 grams only, [3] = 3 grams only, [1,2,3] = 1, 2, and 3- grams.\n",
    "# \t\tself.DIM_DOC2VEC = DIM_DOC2VEC #dimensionality of doc2vec manifold\n",
    "# \t\tself.N_THRESH_CORPUS=N_THRESH_CORPUS # delete any n-grams that appear fewer than N times in the entire corpus\n",
    "# \t\tself.N_THRESH_OUTCOMES=N_THRESH_OUTCOMES # delete any predictors that don't have at least N-many positive and negative examples\n",
    "# \t\tself.TRAIN_INDEX_OVERRIDE = TRAIN_INDEX_OVERRIDE # define a list of indices you want to force to be included as unlabeled data even though they are labeled (ie, these will *not* be used for predictions). Some unlabeled reports are required for d2v training.\"\"\"\n",
    "# \t\tself.SILVER_THRESHOLD=SILVER_THRESHOLD\n",
    "# \t\tself.NAME_UNID_REPORTS = NAME_UNID_REPORTS  \n",
    "# \t\tself.NAME_TEXT_REPORTS = NAME_TEXT_REPORTS\n",
    "\n",
    "# \t\tif(self.DO_BOW==False and self.DO_WORD2VEC==False and self.DO_PARAGRAPH_VECTOR==False): raise ValueError(\"DO_BOW and DO_WORD2VEC and DO_PARAGRAPH_VECTOR cannot both be false\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \tdef infer_labels(self):\n",
    "# \t\t\"\"\"\n",
    "# \t\tInfers labels for unlabeled documents.\n",
    "# \t\tPlease run build_corpus() beforehand.\n",
    "# \t\tArguments:\n",
    "# \t\t\tNone\n",
    "# \t\tReturns:\n",
    "# \t\t\tself.inferred_labels: dataframe containing inferred labels\n",
    "# \t\t\"\"\"\n",
    "\n",
    "# \t\t#get the numerical features of text we need to train models for labels\n",
    "# \t\tself.bow_matrix, self.pv_matrix,self.w2v_matrix,self.accid_list,self.orig_text,self.orig_input=generate_labeled_data_features(\n",
    "# \t\t\t\t\t\t\t   self.validation_file,\n",
    "# \t\t\t\t\t\t\t   self.labeled_indices,\n",
    "# \t\t\t\t\t\t\t   self.DIM_DOC2VEC,\n",
    "# \t\t\t\t\t\t\t   self.df_data,\n",
    "# \t\t\t\t\t\t\t   self.processed_reports,\n",
    "# \t\t\t\t\t\t\t   self.DO_PARAGRAPH_VECTOR,\n",
    "# \t\t\t\t\t\t\t   self.DO_WORD2VEC, \n",
    "# \t\t\t\t\t\t\t   self.dictionary,\n",
    "# \t\t\t\t\t\t\t   self.corpus,\n",
    "# \t\t\t\t\t\t\t   self.d2vmodel,\n",
    "# \t\t\t\t\t\t\t   self.d2v_inputs)\n",
    "\n",
    "# \t\t#get and process labels for reports\n",
    "# \t\tself.eligible_outcomes_aligned,self.all_outcomes_aligned, self.N_LABELS, self.outcome_header_list = generate_outcomes(\n",
    "# \t\t\tself.validation_file,\n",
    "# \t\t\tself.accid_list,\n",
    "# \t\t\tself.N_THRESH_OUTCOMES)\n",
    "\n",
    "# \t\t#to generate silver standard labels -- use whatever features are generated (word2vec average word embeddings, bow features, paragraph vector matrix)\n",
    "# \t\tif(self.DO_BOW and self.DO_WORD2VEC and self.DO_PARAGRAPH_VECTOR): self.combined=np.hstack((self.bow_matrix,self.w2v_matrix,self.pv_matrix))\n",
    "\n",
    "# \t\tif(self.DO_BOW and self.DO_WORD2VEC and not self.DO_PARAGRAPH_VECTOR): self.combined=np.hstack((self.bow_matrix,self.w2v_matrix))\n",
    "# \t\tif(self.DO_BOW and not self.DO_WORD2VEC and self.DO_PARAGRAPH_VECTOR): self.combined=np.hstack((self.bow_matrix,self.pv_matrix))\n",
    "# \t\tif(not self.DO_BOW and self.DO_WORD2VEC and self.DO_PARAGRAPH_VECTOR): self.combined=np.hstack((self.w2v_matrix,self.pv_matrix))\n",
    "\n",
    "# \t\tif(self.DO_BOW and not self.DO_WORD2VEC and not self.DO_PARAGRAPH_VECTOR): self.combined=self.bow_matrix\n",
    "# \t\tif(not self.DO_BOW and self.DO_WORD2VEC and not self.DO_PARAGRAPH_VECTOR): self.combined=self.w2v_matrix\n",
    "# \t\tif(not self.DO_BOW and not self.DO_WORD2VEC and self. DO_PARAGRAPH_VECTOR): self.combined=self.pv_matrix\t\t\n",
    "\n",
    "# \t\t#create header for combined predictor matrix so we can interpret coefficients\n",
    "# \t\tself.headers=[]\n",
    "# \t\tif(self.DO_BOW): \t\t\t\tself.headers=self.headers + [self.dictionary[i] for i in self.dictionary]\n",
    "# \t\tif(self.DO_WORD2VEC): \t\t\tself.headers=self.headers + [\"W2V\"+str(i) for i in range(0,self.DIM_DOC2VEC)]\n",
    "# \t\tif(self.DO_PARAGRAPH_VECTOR): \tself.headers=self.headers + [\"PV\"+str(i) for i in range(0,self.DIM_DOC2VEC)]\n",
    "\n",
    "\n",
    "# \t\tpred_type = \"combined\" # a label for results\n",
    "# \t\tprint(\"dimensionality of predictor matrix:\"+str(self.combined.shape))\n",
    "\n",
    "# \t\t#run lasso regressions\n",
    "# \t\tself.lasso_models, self.accuracy = calc_auc(self.combined,self.eligible_outcomes_aligned,self.all_outcomes_aligned,  self.N_LABELS, pred_type, self.headers,self.ASSIGNFOLD_USING_ROW)\n",
    "\n",
    "# \t\t#infer labels\t\n",
    "# \t\tself.inferred_binary_labels, self.inferred_proba_labels = write_silver_standard_labels(self.corpus,\n",
    "# \t\t\tself.N_LABELS,\n",
    "# \t\t\tself.eligible_outcomes_aligned,\n",
    "# \t\t\tself.DIM_DOC2VEC,\n",
    "# \t\t\tself.processed_reports,\n",
    "# \t\t\tself.DO_BOW,\n",
    "# \t\t\tself.DO_PARAGRAPH_VECTOR,\n",
    "# \t\t\tself.DO_WORD2VEC,\n",
    "# \t\t\tself.dictionary,\n",
    "# \t\t\tself.d2vmodel,\n",
    "# \t\t\tself.d2v_inputs,\n",
    "# \t\t\tself.lasso_models,\n",
    "# \t\t\tself.accid_list, \n",
    "# \t\t\tself.labeled_indices,\n",
    "# \t\t\tself.df_data,\n",
    "# \t\t\tself.SILVER_THRESHOLD)\n",
    "# \t\treturn self.inferred_binary_labels, self.inferred_proba_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This works, but not as elegant\n",
    "\n",
    "# if predictor_matrix.shape[1]!=len(header):\n",
    "#     print(\"predictor_matrix.shape[1]=\"+str(predictor_matrix.shape[1]))\n",
    "#     print(\"len(header)\"+str(len(header)))\n",
    "#     raise ValueError(\"predictor_matrix shape doesn't match header, investigate\")\n",
    "# all_coef = pd.concat([ pd.DataFrame(header)], axis = 1)\t\n",
    "\n",
    "\n",
    "\n",
    "# train_proportion = 0.6\n",
    "# lasso_models={}\n",
    "# model_types = [\"Lasso\"]\n",
    "\n",
    "# # shuffle the data\n",
    "# eligible_outcomes_aligned.reindex(np.random.permutation(eligible_outcomes_aligned.index)) # swapped out np.random.shuffle(r)\n",
    "\n",
    "# r = list(range(eligible_outcomes_aligned.shape[0]))\n",
    "# np.random.shuffle(r)\n",
    "\n",
    "# assignfold = pd.DataFrame(data=r, columns=['train'])\n",
    "# cutoff = np.floor(train_proportion*eligible_outcomes_aligned.shape[0]).astype(int)\n",
    "\n",
    "# train=assignfold['train']<cutoff\n",
    "# test=assignfold['train']>=cutoff\n",
    "\n",
    "# print(test)\n",
    "# N_TRAIN=eligible_outcomes_aligned.iloc[:cutoff].shape[0]\n",
    "# N_HELDOUT = eligible_outcomes_aligned.iloc[cutoff:].shape[0]\n",
    "\n",
    "# #train = eligible_outcomes_aligned.iloc[:cutoff,[0]]\n",
    "# #test = eligible_outcomes_aligned.iloc[cutoff:,[0]]\n",
    "\n",
    "# print(\"n_train in modeling=\"+str(N_TRAIN))\n",
    "# print(\"n_test in modeling=\"+str(N_HELDOUT))\n",
    "\n",
    "# confusion = pd.DataFrame(data=np.zeros(shape=(eligible_outcomes_aligned.shape[1]*len(model_types),6),dtype=np.int),columns=['Label (with calcs on held out 40 pct)','AUC','True +','False +','True -','False -'])\n",
    "\n",
    "# resultrow=0\n",
    "# i = 0\n",
    "\n",
    "# parameters = { \"penalty\": ['l1'], \n",
    "#                \"C\": [64,32,16,8,4,2,1,0.5,0.25,0.1,0.05,0.025,0.01,0.005]}\n",
    "\n",
    "# cv = StratifiedKFold(n_splits=5)\n",
    "# grid_search = GridSearchCV(LogisticRegression(solver='liblinear'), param_grid=parameters, scoring='neg_log_loss', cv=cv) ## can change liblinear to \"lbfgs\"\n",
    "# grid_search.fit(predictor_matrix[train,:],np.array(eligible_outcomes_aligned.ix[train,i]))\t\t\t\t\n",
    "# best_parameters0 = grid_search.best_estimator_.get_params()\n",
    "# model0 = LogisticRegression(**best_parameters0)\t\t\t\t\t\n",
    "                 \n",
    "# model0.fit(predictor_matrix[np.array(train),:],eligible_outcomes_aligned.ix[train,i])\n",
    "# pred0=model0.predict_proba(predictor_matrix[np.array(test),:])[:,1]\n",
    "# coef = pd.concat([ pd.DataFrame(headers),pd.DataFrame(np.transpose(model0.coef_))], axis = 1)\t\n",
    "# df0 = pd.DataFrame({'predict':pred0,'target':eligible_outcomes_aligned.ix[test,i], 'label':all_outcomes_aligned['Accession Number'][test]})\n",
    "\n",
    "# calc_auc=roc_auc_score(np.array(df0['target']),np.array(df0['predict']))\n",
    "# save_name=str(list(eligible_outcomes_aligned.columns.values)[i])\n",
    "# target_predicted=''.join(e for e in save_name if e.isalnum())\n",
    "\n",
    "# # confusion: outcome TP TN FP FN\n",
    "# thresh = np.mean(df0['target'])\n",
    "# FP=0\n",
    "# FN=0\n",
    "# TP=0\n",
    "# TN=0\n",
    "\n",
    "# for j in df0.index:\n",
    "#     cpred=df0.ix[j][0]\n",
    "#     ctarget = df0.ix[j][1]\n",
    "\n",
    "#     if cpred>=thresh and ctarget==1:\n",
    "#         TP+=1\n",
    "#     if cpred<thresh and ctarget==1:\n",
    "#         FN+=1\n",
    "#     if cpred>=thresh and ctarget==0:\n",
    "#         FP+=1\n",
    "#     if cpred<thresh and ctarget==0:\n",
    "#         TN+=1\n",
    "\t\t\t\t\t\t\n",
    "# #save results\t\t\n",
    "# confusion.iloc[resultrow,0]=list(eligible_outcomes_aligned.columns.values)[i]\n",
    "# confusion.iloc[resultrow,1]=calc_auc\n",
    "# confusion.iloc[resultrow,2]=TP\n",
    "# confusion.iloc[resultrow,3]=FP\n",
    "# confusion.iloc[resultrow,4]=TN\n",
    "# confusion.iloc[resultrow,5]=FN\n",
    "            \n",
    "    \n",
    "# model0 = LogisticRegression(**best_parameters0)\t\n",
    "# model0.fit(predictor_matrix,eligible_outcomes_aligned.ix[:,i])                \n",
    "# lasso_models[i]=model0\n",
    "\n",
    "# # resultrow+=1\n",
    "\n",
    "# confusion.set_index(confusion.columns[0],inplace=True)\n",
    "# # return lasso_models, confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
